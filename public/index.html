<!DOCTYPE html>
<html>
<head>
<link href="https://fonts.googleapis.com/css?family=Open+Sans" rel="stylesheet" type="text/css">
<style>
  body {
    font-family: 'Open+Sans', sans;
    font-size: 20px;
  }
</style>
<title>Age At Home</title>
</head>
<!-- start Intercom -->
<script> window.intercomSettings = { app_id: "qhj4pwpj" }; </script>
<script>(function(){var w=window;var ic=w.Intercom;if(typeof ic==="function"){ic('reattach_activator');ic('update',intercomSettings);}else{var d=document;var i=function(){i.c(arguments)};i.q=[];i.c=function(args){i.q.push(args)};w.Intercom=i;function l(){var s=d.createElement('script');s.type='text/javascript';s.async=true;s.src='https://widget.intercom.io/widget/qhj4pwpj';var x=d.getElementsByTagName('script')[0];x.parentNode.insertBefore(s,x);}if(w.attachEvent){w.attachEvent('onload',l);}else{w.addEventListener('load',l,false);}}})()</script>
<!-- end Intercom -->
<!-- start Mixpanel -->
<script type="text/javascript">(function(e,b){if(!b.__SV){var a,f,i,g;window.mixpanel=b;b._i=[];b.init=function(a,e,d){function f(b,h){var a=h.split(".");2==a.length&&(b=b[a[0]],h=a[1]);b[h]=function(){b.push([h].concat(Array.prototype.slice.call(arguments,0)))}}var c=b;"undefined"!==typeof d?c=b[d]=[]:d="mixpanel";c.people=c.people||[];c.toString=function(b){var a="mixpanel";"mixpanel"!==d&&(a+="."+d);b||(a+=" (stub)");return a};c.people.toString=function(){return c.toString(1)+".people (stub)"};i="disable time_event track track_pageview track_links track_forms register register_once alias unregister identify name_tag set_config people.set people.set_once people.increment people.append people.union people.track_charge people.clear_charges people.delete_user".split(" ");
for(g=0;g<i.length;g++)f(c,i[g]);b._i.push([a,e,d])};b.__SV=1.2;a=e.createElement("script");a.type="text/javascript";a.async=!0;a.src="undefined"!==typeof MIXPANEL_CUSTOM_LIB_URL?MIXPANEL_CUSTOM_LIB_URL:"file:"===e.location.protocol&&"//cdn.mxpnl.com/libs/mixpanel-2-latest.min.js".match(/^\/\//)?"https://cdn.mxpnl.com/libs/mixpanel-2-latest.min.js":"//cdn.mxpnl.com/libs/mixpanel-2-latest.min.js";f=e.getElementsByTagName("script")[0];f.parentNode.insertBefore(a,f)}})(document,window.mixpanel||[]);
mixpanel.init("8ce3a282a575094e41bbc4b4b0f4bf9e");
mixpanel.track("home");
</script>
<!-- end Mixpanel -->
<body>
<a href="https://cognitivebuild.bluefundit.com/project/56ee0073f6ec6de43b0d6344">
<img width="10%" src="images/age-at-home.jpg">
</a>
<h1>
Age-At-Home
</h1>
<h2>What is it?</h2>
<p>
Improve the elderlys' ability to age at home through understanding of daily activities inferred from passive sensor analysis.
<h2>
How it Works
</h2>
<p>
The need for helping elderly individuals or couples remain in their home is increasing as our global population ages.  Cognitive processing offers opportunities to assist the elderly by processing information to identify opportunities for caregivers to offer assistance and support.
<p>
Rather than depending on sensors worn on the body (and needing to be not forgotten, recharged, etc..) or installing sensors on individual devices (e.g. sink, cabinet, refrigerator, etc..), this solution utilizes passive monitoring devices, notably video camera(s) with multi-channel microphones, to sense activity, record events, and build a model of normative behavior.
<p>
<img width="75%" src="images/basic-scenario.png">
<table>
<tr valigh="top"><td width="70%">
Initially we intend to monitor the kitchen and recognizes the presence of a person (not an individual) in the room. From this simple event detection we will build a normative baseline of daily activity and detect when that daily activity exhibits aberrations (e.g. no activity in kitchen after +2 std. dev. past median time).
The visual recognition algorithm will run on the local device (e.g. RaspberryPi with camera), the issues of round-trip latency to the cloud, or bandwidth required, or security or privacy concerns, will be eliminated.  Only events generated from this recognition will be sent to the cloud to build (and update) the normative behavior model.
This initial scenario may be easily extended to other passive monitoring capabilities, e.g. audio, motion (sonar), electrical circuit, , ... as well as deployment in other area, e.g. entry way, bathroom, hallway, etc.. to provide support for additional scenarios, e.g. medication adherence, diet, exercise, ... 
</td>
<td>
<img width="75%" src="images/bellcurve.png">
</td>
</tr>
</table>
<p>
<h2>System Overview</h2>
<p>
The solution is patterned on a "do-it-yourself" (DIY) approach and utilizes inexpensive hardware, open source software, and free services from the IBM BlueMix cloud.  The local device is comprised of a RaspberryPi computer and PlayStation3 Eye USB camera with four (4) internal microphones.  Total cost of hardware is under US$80 on-line.
<br>
<img width="75%" src="images/system-overview.png">
<p>
The IBM BlueMix cloud provides services to analyze the images through the Watson cognitive portfolio, notably the AlchemyImage and VisualInsights recognition services.  In addition, Cloudant provides a NoSQL repository for the JavaScript object-notation (JSON) data produced from the event and the two image analysis algorithms.
<p>
BlueMix also provides the dashDB hybrid relational data warehousing service that automatically replicates from the Cloudant repository and provides an SQL interface for SELECT, PROJECT and JOIN.  These SQL services can also be consumed by Watson Analytics and other third-party software packages (e.g. Looker).
<p>
Also on BlueMix, the IBM Internet of Things Foundation (IOTF) platform and associated Real-Time Insights (RTI) provide device registration and system status monitoring (1s intervals) for the RaspberryPi.  General purpose conditionals can be applied for integration with email, IFTTT (www.ifttt.com), Node.Red and arbitrary web-hook.
<p>
[IN PROGRESS] The BlueMix container service provides the run-time environment that processes the Cloudant event data and asynchronously builds the statistical model of normal and abnormal behaviour
and enables configuration for event notification (still under development).
<p>
[NOT SHOWN] This web site is also running on the IBM BlueMix CloudFoundry platform-as-a-service (PAAS), coordinating credentialing, billing and operational metrics across the service catalog.  In addition, this site utilizes Mixpanel (www.mixpanel.com) and Intercom.io (www.intercom.io) to provide user tracking and near-line chat (n.b. look in lower right corner for chat icon).
<p>
GitHub repositories are publically accessible at:
<ul>
<li><a href="https://github.com/dcmartin/AgeAtHome">RaspberryPi container for resin.io deployment</a>.
<li><a href="https://github.com/dcmartin/age-at-home">BlueMix CloudFoundry application</a>.
</ul>
<h2>
Initial Results
</h2>
<p>
With almost five (5) weeks of data collected patterns are emerging.  Added new database to Cloudant (rough-fog-stats)
to store the statistical values.
Link to data (rough-fog is the device DB name in Cloudant):
<ul>
<li>All events (need to add <code>?include_docs=true</code> to see event details (<a href="https://538e7925-b7f5-478b-bf75-2f292dcf642a-bluemix.cloudant.com/rough-fog/_all_docs">rough-fog</a>)
<li>All classification statistics ({count, mean, sum, stdev} for each of 7 days x 96 time-intervals: <a href="https://538e7925-b7f5-478b-bf75-2f292dcf642a-bluemix.cloudant.com/rough-fog-stats/_all_docs">rough-fog-stats</a>)
<li>Classification statistics for "person" (Alchemy API) (<a href="https://538e7925-b7f5-478b-bf75-2f292dcf642a-bluemix.cloudant.com/rough-fog-stats/person">rough-fog-stats/person</a>)
</ul>
<h2>
Analysis
</h2>
<p>
The statistical model is built initially using the <code><a href="bin/mkclass">mkclass</a></code> script.
The script builds the 'person' classifier statistical model for the 'rough-fog' device by default, but can be parameterize by the device name and either a single classifier, a named classifier set (e.g. 'human' or 'all') or a list of classifiers separated by spaces.  When the model is calculated it is uploaded into device-specific database, e.g. rough-fog-stats, with each classifier model accessed by name (e.g. 'rough-fog-stats/person').
<p>
The results of the <code>mkclass</code> script are JSON and CSV files.  The CSV file for the 'person' classifier is consumed by the Excel spreadsheet to produce the charts below.
<p>
<ul>
<li><a href="data/rough-fog-person.xslx">Excel spreadsheet</a> that processes person.csv file and makes the pretty charts below.
<li>A <a href="https://gist.github.com/parente/7db992fae487d6e665e7b7dca841ffa2">Spark notebook</a> by Peter Parente (peterp@us.ibm.com)
</ul>
<p>
<img width="75%" src="images/spark-graph.png">
<p>
The graphs below are generated in the Excel spreadsheet and visualize the following:
<ol>
<li>All Activity; the sum of 'person' events in the kitchen
<li>Expected Activity; when 'person' count by 'intervals' "near" mean of interval count
<li>Over Activity; when 'person' count by 'interval' is +2SD over mean of interval count
<li>Under Activity; when 'person' count by 'interval' is -2SD under mean of interval count
</ol>
<p>
<table>
<tr>
<td><img width="95%" src="images/person-active.png"></td>
<td><img width="95%" src="images/person-normal-active.png"></td>
</tr>
<tr>
<td><img width="95%" src="images/person-over-active.png"></td>
<td><img width="95%" src="images/person-under-active.png"></td>
</tr>
</table>
<h3>
Web Services
</h3>
<ul>
<li>
Calculates / updates statistical model for device and classifier
<a href="http://www.dcmartin.com/CGI/aah-stats.cgi?db=rough-fog&id=person"><code>aah-stats?db=rough-fog&id=person</code></a>
<li>
Calculates / updates statistical model for days of week or device and classifier
<a href="http://www.dcmartin.com/CGI/aah-stats.cgi?db=rough-fog&id=person&day=all"><code>aah-stats?db=rough-fog&id=person&day=all</code></a>
<li>
Calculates / updates statistical model for intervals of day for device and classifier
<a href="http://www.dcmartin.com/CGI/aah-stats.cgi?db=rough-fog&id=person&interval=all"><code>aah-stats?db=rough-fog&id=person&interval=all</code></a>
<li>
Calculate / update list of all classifiers for device (e.g. "db=rough-fog")
<a href="http://www.dcmartin.com/CGI/aah-classifiers.cgi?db=rough-fog"><code>aah-classifiers</code></a> 
</ul>
The id= argument can be specified with any of the classifiers.  The day= and interval= arguments can be specified with &quot;all&quot; or a number for day (0-6) or interval (0-95).
<p>
<img width="75%" src="images/command-line.png">
<p>

<h3>
Data and Scripts
</h3>
<ul>
<li><a href="data/rough-fog-person.csv">rough-fog-person.csv</a> - Pivot table of sum of 'person' events across all 15 minutes 'intervals' per day with count of weeks in sum
<li><a href="data/rough-fog.json">rough-fog.json</a> - This file is the JSON 'events' from the Cloudant database retrieved by the <code>getjson2csv</code> script; 
the DB can be specified on the command line
<li><a href="data/rough-fog.csv">rough-fog.csv</a> (<a href="data/rough-fog-stat.csv">statistics</a>) - 
These two files are output of JSON to CSV conversion and the calculation of statistics on the columns; these files are produced by the <code>getjson2csv</code> script; [ <DB> [ "none" | <operations>+ ]] are options for DB name and if/what statistics to calculate
<li><a href="data/rough-fog-class-values.csv">rough-fog-class-values.csv</a> (<a href="data/rough-fog-classes.txt">all classes</a>) - These two files are the classifiers and values for all 'events' in the CSV table (i.e. rough-fog) as well as a list of all classifiers, including null (&quot;&quot)
<li><a href="data/rough-fog-day-ampm.csv">rough-fog-day-ampm.csv</a> - This file is the calculation of AM or PM and day of week (e.g. Sunday) for all 'events' in the CSV table
<li><a href="data/rough-fog-person-hour.csv">rough-fog-person-hour.csv</a> (<a href="data/rough-fog-person-hour.json">JSON</a>) - This file is the calculation of the 'person' classifier (n.b. Alchemy API) statistics for all hours of the week for both AM and PM intervals.
<li><a href="data/rough-fog-person-interval.csv">rough-fog-person-interval.csv</a> (<a href="data/rough-fog-person-interval.json">JSON</a>) - This file is the calculation of the 'person' classifier (n.b. Alchemy API) in increments of 15 minutes (interval) across all days of the week for both AM and PM intervals.
</ul>
<p>
List of shell scripts - listed in the order they should be run:
<ul>
<li><a href="bin/mkclass"><code>mkclass</code></a> - Script to create rough-fog-person.csv file and all dependencies including download from Cloudant; defaults to 'rough-fog', 'person' (24 hours TTL for refresh, but can be changed in script)
<li><a href="bin/getjson2csv"><code>getjson2csv</code></a> - Script to pull JSON from Cloudant and convert to CSV, including calculating statistics and encoding as CSV.
<li><a href="bin/mkclassvalues"><code>mkclassvalues</code></a> - Script to pull all VisualInsights and Alchemy "classifiers" and create CSV with class, score, time, date and event ID; can be specialized with DB and one or more classifiers; if only one classifier is specified, it assume Alchemy only (e.g. 'person').
<li><a href="bin/mkintervals"><code>mkintervals</code></a> - Script to distinguish event time into 'day' of week, 'ampm' AM or PM, and 15 minute 'interval' in addition to default 'doc/hour' bucket
<li><a href="bin/mkclassintervals"><code>mkclassintervals</code></a> - Script to calculate statistics for one classifier (default 'person') occurence by bucket (default 'doc/hour'; option 'interval') across AM and PM and days of week; note that 'doc/hour' is converted to simply 'hour' for output file.
<li><a href="bin/new2json"><code>new2json</code></a> (<a href="bin/new2json.awk"><code>AWK</code></a>)
- Convert the CSV results of <code>mkclass</code> (e.g. <a href="data/rough-fog-person.csv">rough-fog-person.csv</a>) to a JSON object 
(e.g. <a href="data/rough-fog-person.json">rough-fog-person.json</a>)
</ul>
<h2>
Watson Analytics
</h2>
<p>
The process of preparing JSON data for Watson Analytics is cumbersome. While replication from Cloudant into dashDB is provided and dashDB can be accessed from WA
(n.b. you need a paid account), the refinement capabilities in WA are insufficient for any non-trivial transformation (e.g. time into day of week).
I wrote UNIX shell scripts to download the JSON data, convert to CSV, calculate statistics on the columns -- also not provided by WA, extract classifiers' scores for all events, 
and catagorize events into day-of-week and AM-PM <i>bins</i>.  These scripts can take a long time to run on a laptop.
<p>
<table>
<tr>
<td align="center">
<img width="95%" src="images/mean-day-ampm.png">
<br><i>Trend of mean time for person in kitchen over days of week</i>
</td>
<td align="center">
<img width="95%" src="images/stdev-day-ampm.png">
<br><i>Trend of standard deviation for person in kitchen over days of week</i>
</td>
</tr>
</table>
<p>
These images are created using <a href="https://watson.analytics.ibmcloud.com/">Watson Analytics</a>.  It is simple to get a free account and load the CSV files.
Here are some additional visualizations of the data.
<br>
<table width="100%">
<tr valign="top">
<td width="30%" align="center">
<figure>
    <img width="95%" src="images/score-hour-classifier.png">
    <figcaption>Primary Classifiers</figcaption>
</figure>
</td>
<td width="30%" align="center">
<figure>
    <img width="95%" src="images/hour-classifier-relationship.png">
    <figcaption>Relationship between hour, day and classifier</figcaption>
</figure>
</td>
<td width="30%" align="center">
<figure>
    <img width="95%" src="images/classifier-heatmap.png">
    <figcaption>Heatmap of classifiers</figcaption>
</figure>
</td>
</tr>
</table>
<h3>Looker</h3>
One of IBM business partners, <a href="http://www.looker.com">Looker</a>, provides a GUI interface to <a href="http://www-01.ibm.com/software/data/dashdb/">dashDB</a>.
A kind soul at Looker, Erin, analyzed the data in the rough-fog Cloudant database through its dashDB replication warehouse and provided the following example.
<p>
<img src="images/looker.png" width="75%">
<br>
<i>Static image from Looker UI</i>
<p>
<iframe src='https://ibmcds.looker.com/embed/public/WkqT2NkmksNyVCQfjTBKB37gFbQwHsB6' width='600' height='338' frameborder='0'></iframe>
<br>
<i>Live analysis using Looker</i>
<p>
<iframe src='https://ibmcds.looker.com/embed/public/WkqT2NkmksNyVCQfjTBKB37gFbQwHsB6?type=table' width='600' height='338' frameborder='0'></iframe>
<br>
<i>Associated live data frame</i>
<p>
<h2>Examples</h2>
Image captured using motion detection algorithm based on changes in pixel count (bounding box around centroid identifed).
<p>
<img width="50%" alt="High confidence example" src="images/hiconf.png">
<br>
<img width="50%" alt="Low confidence example" src="images/loconf.png">
<h2>Equipment</h2>
The necessary equipment for this project is relatively inexpensive:
A RaspberryPi3 with 32 GB uSD card and Playstation3 Eye USB camera
<p>
<img width="50%" src="images/camera.png">
<br>
<i>Installation on kitchen shelf</i>
<p>
<ul>
<li>RaspberryPi3 ~ US$45.00
<li>Enclosure, uSD card, power-supply ~ US$30
<li>Playstation3 Eye camera ~ US$5 (WOW!)
</ul>
<b>TOTAL COST: ~ US$80!</b>  For comparison, a DropCam from Nest (aka Google) is ~ US$199.
<p>
<img width="25%" src="images/Rp3.png">
<br>
<img width="25%" src="images/Rpi3 case.png">
<img width="25%" src="images/uSD-32bg.png">
<br>
<img width="25%" src="images/Rpi3 power.png">
<img width="25%" src="images/ps3eyecamera.png">
<p>
<h2>Infrastructure</h2>
We are making use of <a href="http://resin.io/">resin.io</a> to manage the build and deployment process to the Raspberry Pi devices.
<p>
The resin.io service provides a customizable base image with which to "flash" the uSD card for the RaspberryPi.  The image may be configured 
with the SSID and password for the local WiFi network.
<p>
The "AgeAtHome" application we have defined provides a context in which devices participate.  Each device is assigned to one application.
Once a device has been flashed and booted, it connects to the resin.io service and presents itself within the application context.
<p>
<img width="24%" src="images/resin-app.png">
<p>
Each device associated with the application can be inspected, including summary status and logs (e.g. stderr).
<p>
<img width="75%" src="images/resin-detail.png">
<p>
Including the ability to ssh(1) into a terminal for command line interface:
<br>
<img width="75%" src="images/terminal.png">
<br>
<i>Listing of motion detection volume data in file system</i>


<h2>IBM IoTF Platform</h2>
I added the IBM IoT Foundation <a href="https://developer.ibm.com/recipes/tutorials/raspberry-pi-4/">Quickstart for Raspberry Pi</a>
to the environment and you can see a <a href="https://quickstart.internetofthings.ibmcloud.com/#/device/b827eb7bf9fb"> live stream </a>
of instrumentation data.  The dashboard below is shown once a device is registered to a BlueMix account and affiliated with an organization (another level of indirection 
off your BlueMix account).
<p>
<img width="50%" src="images/iotf-platform-dashboard.png">
<br> <i>IBM IoTF Platform Dashboard</i>
<p>
Changes were made to both Dockerfile as well as initial script to enable IoTF/QS and sample C program only sends system status.  Will need to change
the sample program to progres HTTP requests to send any JSON payloads (i.e. our events).
<h3>
IBM IOTF Real-time Insights
</h3>
The IBM IOTF Real-time Insights capabilities can be linked to the IOTF Platform 
through a shared repository for the JSON events received by the platform; the JSON objects in that repository provide schemas for payload processing.
The IOTF-RTI environment provides for rules to be specified in conjunction with JSON
payload values using numeric comparison to static values, other payload values, and context parameters (n.b. unsure where or how these values are set).
<p>
<img width="50%" src="images/iotf-realtime-insights.png">
<br><i>IBM IOTF Real-time Insights <i>rule</i> specification</i>
<p>
<img width="50%" src="images/iotf-realtime-insights-condition.png">
<br><i>IBM IOTF Real-time Insights <i>rule</i> <b>condition</b> specification</i>
<p>
<img width="50%" src="images/iotf-realtime-insights-action.png">
<br><i>IBM IOTF Real-time Insights <i>rule</i> <b>action</b> specification</i>
<p>

<h2>IBM Cognitive Build Projects</h2>
<p>
The AgeAtHome project received internal virtual funding US$196,985 from 384 investors.  Thank you to all the investors.
<p>Other interesting projects are listed below:
<p>
<table>
<tr valign="bottom">
<td width="20%">
<a href="https://cognitivebuild.bluefundit.com/project/56ede1fc8176a1ae2897f15d"><img width="50%" src="images/cognitive-home.png"><br><i>Cognitive Home</i></a>
</td>
<td width="20%">
<a href="https://cognitivebuild.bluefundit.com/project/56edbc785f084a51131dd4e7"><img width="50%" src="images/dementia-detector.jpg"><br><i>Dementia Detector</i></a>
</td>
<td width="20%">
<a href="https://cognitivebuild.bluefundit.com/project/56edab058e0e35fb0b732bbb"><img width="50%" src="images/watson-globe.png"><br><i>Watson Globe</i></a>
</td>
<td width="20%">
<a href="https://cognitivebuild.bluefundit.com/project/56ede6e784cafb822bb1ea9d"><img width="50%" src="images/cognitive-companion.png"><br><i>Cognitive Companion</i></a>
</td>
<td width="20%">
<a href="https://cognitivebuild.bluefundit.com/project/56edce14d08dde1920edbc53"><img width="50%" src="images/health-buddy.png"><br><i>Health Buddy</i></a>
</td>
</tr>
<tr valign="bottom">
<td width="20%">
<a href="https://cognitivebuild.bluefundit.com/project/56edcd6a2b3b2e371d18315d"><img width="50%" src="images/recover-recommender.jpg"><br><i>Recovery Recommender</i></a>
</td>
<td width="20%">
<a href="https://cognitivebuild.bluefundit.com/project/56edc4e53ac2fcc31848dd2c"><img width="50%" src="images/pratchett.png"><br><i>Pratchett</i></a>
</td>
<td width="20%">
<a href="https://cognitivebuild.bluefundit.com/project/56edf89762ad9a6736aa912d"><img width="50%" src="images/cognitive-caregiving.jpg"><br><i>Cognitive Caregiving</i></a>
</td>
<td width="20%">
<a href="https://cognitivebuild.bluefundit.com/project/56edb8f75f084a51131dd477"><img width="50%" src="images/blue-angel.png"><br><i>Blue Angel</i></a>
</td>
</tr>
</table>


</body>
</html>
